{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import initializers, regularizers, constraints\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import GlobalMaxPool1D, Dense, Dropout, Conv1D, BatchNormalization\n",
    "import tensorflow as tf\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model_1():\n",
    "    maxlen = 3321\n",
    "    class_num = 1\n",
    "    last_activation = 'sigmoid'\n",
    "    input = Input((maxlen, 20))\n",
    "\n",
    "    x = Conv1D(256, 32, activation='relu', strides=1, padding='same')(input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = GlobalMaxPool1D()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    y = Conv1D(256, 16, activation='relu', strides=1, padding='same')(input)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = GlobalMaxPool1D()(y)\n",
    "    y = Dropout(0.5)(y)\n",
    "\n",
    "    z = Conv1D(256, 8, activation='relu', strides=1, padding='same')(input)\n",
    "    z = BatchNormalization()(z)\n",
    "    z = GlobalMaxPool1D()(z)\n",
    "    z = Dropout(0.5)(z)\n",
    "\n",
    "    t = tf.keras.layers.Concatenate()([x, y, z])\n",
    "    t = Dense(64, activation='relu')(t)\n",
    "    t = Dense(16, activation='relu')(t)\n",
    "    output = Dense(class_num, activation=last_activation)(t)\n",
    "    model = Model(inputs=input, outputs=output)\n",
    "    model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "                  optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model_2():\n",
    "    maxlen = 3321\n",
    "    class_num = 6\n",
    "    last_activation = 'softmax'\n",
    "    input = Input((maxlen, 20))\n",
    "\n",
    "    x = Conv1D(256, 32, activation='relu', strides=1, padding='same')(input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = GlobalMaxPool1D()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    y = Conv1D(256, 16, activation='relu', strides=1, padding='same')(input)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = GlobalMaxPool1D()(y)\n",
    "    y = Dropout(0.5)(y)\n",
    "\n",
    "    z = Conv1D(256, 8, activation='relu', strides=1, padding='same')(input)\n",
    "    z = BatchNormalization()(z)\n",
    "    z = GlobalMaxPool1D()(z)\n",
    "    z = Dropout(0.5)(z)\n",
    "\n",
    "    t = tf.keras.layers.Concatenate()([x, y, z])\n",
    "    t = Dense(64, activation='relu')(t)\n",
    "    t = Dense(16, activation='relu')(t)\n",
    "    output = Dense(class_num, activation=last_activation)(t)\n",
    "    model = Model(inputs=input, outputs=output)\n",
    "    model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "                  optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature(seq_matrix):\n",
    "    \"\"\"将字符编码为整数\n",
    "    \"\"\"\n",
    "    one_hot = []\n",
    "    ind_to_char = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y']\n",
    "    char_to_ind = {char: i for i, char in enumerate(ind_to_char)}\n",
    "    # 整数编码\n",
    "    integer_encoded = [char_to_ind[char] for char in seq_matrix]\n",
    "    for value in integer_encoded:\n",
    "        letter = tf.eye(len(ind_to_char))\n",
    "        one_hot.append(letter[value])\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_padding(data):\n",
    "    data_new = []\n",
    "    maxlen = 3321\n",
    "    seq_new = tf.pad(data,[[0, maxlen-len(data)], [0, 0]])\n",
    "    data_new.append(seq_new)\n",
    "    return data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_predict(id_seqs):\n",
    "    id = []\n",
    "    is_hsp = []\n",
    "    prob = []\n",
    "    is_hsp20 = []\n",
    "    is_hsp40 = []\n",
    "    is_hsp60 = []\n",
    "    is_hsp70 = []\n",
    "    is_hsp90 = []\n",
    "    is_hsp100 = []\n",
    "    seq_len = len(id_seqs)\n",
    "    for i in range(seq_len):\n",
    "        record = id_seqs[i]\n",
    "        if i % 2 == 0:\n",
    "            if record.startswith('>'):\n",
    "                continue\n",
    "            else:\n",
    "                return 0, \"format error, must in fasta format\"\n",
    "        if i % 2 == 1:\n",
    "            if len(record) == 0:\n",
    "                return 2, \"Please enter the sequence of 20 amino acids\"\n",
    "            if len(record) <= 3321:\n",
    "                seq = record.upper()\n",
    "                for seq_one in seq:\n",
    "                    if seq_one in 'ACDEFGHIKLMNPQRSTVWY':\n",
    "                        continue\n",
    "                    else:\n",
    "                        return 2, \"Please enter the sequence of 20 amino acids\"\n",
    "                fea_df = get_feature(seq)\n",
    "                fea_padding = seq_padding(fea_df)\n",
    "                feature = np.array(fea_padding)\n",
    "                model_1 = define_model_1()\n",
    "                model_1.load_weights('HSP/models/hsp_model.h5')\n",
    "                res_1 = model_1.predict(feature)\n",
    "                id.append(id_seqs[i - 1].split('>')[-1])\n",
    "                prob.append(np.round(np.squeeze(res_1),4))\n",
    "                if res_1 > 0.5:\n",
    "                    is_hsp.append(\"True\")\n",
    "                    model_2 = define_model_2()\n",
    "                    model_2.load_weights(models/hsp_class_model.h5')\n",
    "                    res_2 = model_2.predict(feature)\n",
    "                    for k in range(len(res_2)):\n",
    "                        res_2[k][np.argmax(res_2[k])] = 1\n",
    "                        res_2[k][res_2[k] < 1] = 0\n",
    "                        str_res_2 = res_2.astype(str)\n",
    "                        if str_res_2[0][0] == \"1.0\":\n",
    "                            is_hsp20.append(\"True\")\n",
    "                        else:\n",
    "                            is_hsp20.append(\"-\")\n",
    "                        if str_res_2[0][1] == \"1.0\":\n",
    "                            is_hsp40.append(\"True\")\n",
    "                        else:\n",
    "                            is_hsp40.append(\"-\")\n",
    "                        if str_res_2[0][2] == \"1.0\":\n",
    "                            is_hsp60.append(\"True\")\n",
    "                        else:\n",
    "                            is_hsp60.append(\"-\")\n",
    "                        if str_res_2[0][3] == \"1.0\":\n",
    "                            is_hsp70.append(\"True\")\n",
    "                        else:\n",
    "                            is_hsp70.append(\"-\")\n",
    "                        if str_res_2[0][4] == \"1.0\":\n",
    "                            is_hsp90.append(\"True\")\n",
    "                        else:\n",
    "                            is_hsp90.append(\"-\")\n",
    "                        if str_res_2[0][5] == \"1.0\":\n",
    "                            is_hsp100.append(\"True\")\n",
    "                        else:\n",
    "                            is_hsp100.append(\"-\")\n",
    "                else:\n",
    "                    is_hsp.append(\"False\")\n",
    "                    is_hsp20.append(\"-\")\n",
    "                    is_hsp40.append(\"-\")\n",
    "                    is_hsp60.append(\"-\")\n",
    "                    is_hsp70.append(\"-\")\n",
    "                    is_hsp90.append(\"-\")\n",
    "                    is_hsp100.append(\"-\")\n",
    "            else:\n",
    "                id.append(id_seqs[i - 1].split('>')[-1])\n",
    "                is_hsp.append(\"-\")\n",
    "                prob.append(\"Sequence length must be <= 3321\")\n",
    "                is_hsp20.append(\"-\")\n",
    "                is_hsp40.append(\"-\")\n",
    "                is_hsp60.append(\"-\")\n",
    "                is_hsp70.append(\"-\")\n",
    "                is_hsp90.append(\"-\")\n",
    "                is_hsp100.append(\"-\")\n",
    "    res_df = pd.DataFrame(\n",
    "        columns=['id', 'is_hsp', 'prob', 'is_hsp20', 'is_hsp40', 'is_hsp60', 'is_hsp70', 'is_hsp90', 'is_hsp100'])\n",
    "    res_df.id = id\n",
    "    pro = []\n",
    "    for z in prob:\n",
    "        pro.append(str(z))\n",
    "    res_df.is_hsp = is_hsp\n",
    "    res_df.prob = pro\n",
    "    res_df.is_hsp20 = is_hsp20\n",
    "    res_df.is_hsp40 = is_hsp40\n",
    "    res_df.is_hsp60 = is_hsp60\n",
    "    res_df.is_hsp70 = is_hsp70\n",
    "    res_df.is_hsp90 = is_hsp90\n",
    "    res_df.is_hsp100 = is_hsp100\n",
    "    return 1, res_df.to_json(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    data = \"fastafile\"\n",
    "    predict_result = run_predict(data)\n",
    "    print(predict_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
